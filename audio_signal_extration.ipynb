{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# install also ffmpeg in the system (https://ffmpeg.org/download.html) for extracting the signal from the audio files.\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_signal(file_path, start_sample=31380, end_sample=100000):\n",
    "    \"\"\"\n",
    "    Extracts the audio signal from a file, crops it to a specified range, \n",
    "    and pads or truncates to ensure uniform length.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the audio file.\n",
    "        start_sample (int): The starting sample index for cropping the audio signal.\n",
    "        end_sample (int): The ending sample index for cropping the audio signal.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A numpy array containing the cropped and padded audio signal.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use ffmpeg to extract the audio and convert it to wav format in memory\n",
    "        out, _ = (\n",
    "            ffmpeg\n",
    "            .input(file_path)\n",
    "            .output('pipe:', format='wav')\n",
    "            .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "\n",
    "        # Convert the audio signal to a numpy array (assuming 16-bit PCM)\n",
    "        signal = np.frombuffer(out, dtype=np.int16)\n",
    "        \n",
    "        # Crop the signal between the specified start and end samples\n",
    "        signal_cropped = signal[start_sample:end_sample]\n",
    "\n",
    "        # Check if the cropped signal is shorter than the desired end_sample length\n",
    "        if len(signal_cropped) < (end_sample - start_sample):\n",
    "            # Pad the signal with zeros if it is shorter\n",
    "            signal_cropped = np.pad(signal_cropped, (0, (end_sample - start_sample) - len(signal_cropped)), 'constant')\n",
    "        else:\n",
    "            # Truncate the signal if it is longer\n",
    "            signal_cropped = signal_cropped[:(end_sample - start_sample)]\n",
    "\n",
    "        return signal_cropped\n",
    "\n",
    "    except ffmpeg.Error as e:\n",
    "        print(f\"Error extracting audio signal from {file_path}: {e.stderr.decode()}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_signal(file_path, start_sample=31380, end_sample=100000):\n",
    "    \"\"\"\n",
    "    Extracts the audio signal from a file, crops it to a specified range, \n",
    "    and pads or truncates to ensure uniform length.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the audio file.\n",
    "        start_sample (int): The starting sample index for cropping the audio signal.\n",
    "        end_sample (int): The ending sample index for cropping the audio signal.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A numpy array containing the cropped and padded audio signal.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use ffmpeg to extract the audio and convert it to wav format in memory\n",
    "        out, _ = (\n",
    "            ffmpeg\n",
    "            .input(file_path)\n",
    "            .output('pipe:', format='wav')\n",
    "            .run(capture_stdout=True, capture_stderr=True)\n",
    "        )\n",
    "\n",
    "        # Convert the audio signal to a numpy array (assuming 16-bit PCM)\n",
    "        signal = np.frombuffer(out, dtype=np.int16)\n",
    "        \n",
    "        # Crop the signal between the specified start and end samples\n",
    "        signal_cropped = signal[start_sample:end_sample]\n",
    "\n",
    "        # Check if the cropped signal is shorter than the desired end_sample length\n",
    "        if len(signal_cropped) < (end_sample - start_sample):\n",
    "            # Pad the signal with zeros if it is shorter\n",
    "            signal_cropped = np.pad(signal_cropped, (0, (end_sample - start_sample) - len(signal_cropped)), 'constant')\n",
    "        else:\n",
    "            # Truncate the signal if it is longer\n",
    "            signal_cropped = signal_cropped[:(end_sample - start_sample)]\n",
    "\n",
    "        return signal_cropped\n",
    "\n",
    "    except ffmpeg.Error as e:\n",
    "        print(f\"Error extracting audio signal from {file_path}: {e.stderr.decode()}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_audio_dataset(base_path, class_dirs):\n",
    "    \"\"\"\n",
    "    Creates a dataset of audio signals extracted from files organized in class directories.\n",
    "    \n",
    "    Parameters:\n",
    "        base_path (str): Path to the base directory containing class subdirectories.\n",
    "        class_dirs (list): List of class subdirectories, where each subdirectory contains audio files.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A 2D numpy array where each row represents an audio signal.\n",
    "        np.ndarray: A 1D numpy array containing the class labels for each audio signal.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    \n",
    "    for label, class_dir in enumerate(class_dirs):\n",
    "        class_path = os.path.join(base_path, class_dir)\n",
    "        audio_files = sorted(os.listdir(class_path))  # Organize files to ensure consistent order\n",
    "        print(f\"Processing {len(audio_files)} files in {class_dir}...\")\n",
    "        for audio_file in audio_files:\n",
    "            audio_path = os.path.join(class_path, audio_file)\n",
    "            # Extract the audio signal using the extract_audio_signal function\n",
    "            signal = extract_audio_signal(audio_path)\n",
    "            \n",
    "            if signal is not None:\n",
    "                dataset.append(signal)\n",
    "                labels.append(label)  # Add the corresponding class label\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    dataset = np.array(dataset)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio_dataset_to_csv(signals, labels, output_file):\n",
    "    \"\"\"\n",
    "    Saves the audio dataset and labels to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        signals (np.ndarray): A 2D numpy array where each row represents an audio signal.\n",
    "        labels (np.ndarray): A 1D numpy array containing the class labels for each audio signal.\n",
    "        output_file (str): The path to the output CSV file.\n",
    "    \"\"\"\n",
    "    # Create a pandas DataFrame from the dataset and labels\n",
    "    df = pd.DataFrame(signals)\n",
    "    \n",
    "    # Add a column for the labels\n",
    "    df['label'] = labels\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 15 files in abrir...\n",
      "Processing 15 files in fechar...\n",
      "Processing 15 files in ligar...\n",
      "Dataset shape: (45, 68620)\n",
      "Labels shape: (45,)\n"
     ]
    }
   ],
   "source": [
    "base_path = './data/audios'  # base path for the audio files\n",
    "class_dirs = ['abrir', 'fechar', 'ligar']  # class subdirectories\n",
    "\n",
    "# Create the audio dataset\n",
    "signals, labels = create_audio_dataset(base_path, class_dirs)\n",
    "\n",
    "print(f\"Dataset shape: {signals.shape}\")  # Should be (45, length_signal)\n",
    "print(f\"Labels shape: {labels.shape}\")    # Deve ser (45,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to data/audio_signals_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = \"data/audio_signals_dataset.csv\"\n",
    "\n",
    "# Save the audio dataset to a CSV file\n",
    "save_audio_dataset_to_csv(signals, labels, output_file)\n",
    "\n",
    "print(f\"Dataset saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voicecommandsvm-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
